---
title: "Considerations for choosing windows"
author: "Eamon O'Dea"
date: "`r Sys.Date()`"
output: rmarkdown::html_document
bibliography: ews.bib
vignette: >
  %\VignetteIndexEntry{Choosing windows}
  %\VignetteEngine{knitr::rmarkdown_notangle}
  %\VignetteEncoding{UTF-8}
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

```

## Summary of goals

Illustrate how autocorrelation of moving window statistics may be calculated and how this can help determine an appropriate window size for correlation analysis.

## Simulation of data

First let's simulate some surveillance data from the lead-up to an outbreak.
The population size and length of the simulation are chosen to match California in the lead up to the 1991 measles outbreak, but we are mostly just going for a simulation from a simple conceptual model.

```{r sim}

tab <- data.frame(
  gamma_t = c(0, 0), mu_t = c(0, 0), d_t = c(0, 0), eta_t = c(0, 0), 
  beta_par_t = c(0, 1.4e-6 * 10 / 7), p_t = c(0, 0), time = c(0, 10))
foo <- spaero::create_simulator(covar = tab)
pomp::coef(foo)["N_0"] <- 1e7
pomp::coef(foo)["beta_par"] <- 1e-6
pomp::coef(foo)["eta"] <- 3e-6
out <- pomp::simulate(foo, times = seq(0, 10, by = 1 / 52), seed = 1)
out <- as(out, "data.frame")
plot(cases~time, data = out, type = 'h')
```


Clearly, a major outbreak is starting around year 9. Is there warning in the data from the first 7 years?

```{r}
cts <- ts(out$cases, frequency = 52)
sub <- window(cts, end = 7)
plot(sub)

```

## Null model

CSD would manifest in some change in the summary statistics of the time series. A simple null model is that the process generating the data is stationary. We would like to know the distribution of the summary statistics under such a null model to decide if the behavior of the statistics in the observed data is unlikely under such a model.

Stationary time series may be generated by the stationary bootstrap procedure. @politis1994 show that a block bootstraping procedure with geometric block lengths produces a stationary distribution. 

To simulate this data, we must decide on the average block size. @politis1994 decide on this in an example section by setting it equal to about twice the lag at which the autocovariance is not significantly different from zero.

```{r}
acf(sub)
```


According to that rule, an average block size of about 0.6 years seems appropriate for this data. We will use the boot::tsboot() function to resample data according to the stationary bootstrap.


```{r}
set.seed(3)
resamp <- boot::tsboot(sub, identity, R = 300, l = 52 * 0.5, sim = "geom")$t
plot(ts(t(resamp[1:6,]), frequency = 52))
```

The resampled time series look similar to the original in terms of autocorrelation. Now let's estimate the Fourier transform for our resampled time series. We will be able to use to calculate the autocovariance of the summary statistics.

```{r check-basic-fourier-transform-comprehension, echo = FALSE}

foo <- resamp[1,]
r1t <- fft(foo)
N <- length(r1t)
stopifnot(isTRUE(all.equal(Re(fft(r1t, inverse = TRUE) / N), resamp[1,])))

H <- function(N, cvec){
  n <- seq(0, N - 1)
  M <- length(cvec)
  nfreq <- n / N
  ret <- complex(N)
  for (ind in seq_len(M)) {
      ret <- ret + cvec[ind] * exp(-2i * pi * n[ind] * nfreq)
  }
  ret
}

R <- c(1, 1, rep(0, 311)) / 2
filtwind2 <- H(313, c(0.5, 0.5))
stopifnot(isTRUE(all.equal(fft(R), filtwind2)))

Ma2t <- r1t * fft(R)

stopifnot(isTRUE(all.equal(Mod(Ma2t), 
                           Mod(r1t) * Mod(fft(R))))) # PSD is scaled by PSD of respone function

ma2time <- Re(fft(Ma2t, inverse = TRUE)) / N
stopifnot(isTRUE(all.equal(ma2time, 
                           c(foo[N], foo[-N])/2 + c(foo) / 2)))

stopifnot(isTRUE(all.equal(zapsmall(ma2time),
                           zapsmall(convolve(resamp[1,], c(0.5, rep(0, 311), 0.5))))))


# convolution in frequency maps to multiplication in time:

stopifnot(isTRUE(all.equal(zapsmall(Re(fft(convolve(Ma2t, Ma2t) / N^2, inverse = TRUE))),
          zapsmall(ma2time^2))))

```

Let us begin with the mean.

```{r}

N <- dim(resamp)[2]

H <- function(N, cvec){
  n <- seq(0, N - 1)
  M <- length(cvec)
  nfreq <- n / N
  ret <- complex(N)
  for (ind in seq_len(M)) {
      ret <- ret + cvec[ind] * exp(-2i * pi * n[ind] * nfreq)
  }
  ret
}

ma2vec <- rep(1, 2) / 2
filtwind2 <- H(N, ma2vec)

resampT <- apply(resamp, 1, fft)
resampMa2T <- resampT * filtwind2
resampMa2PSD <- Re(rowMeans(resampMa2T * Conj(resampMa2T))) / N ^ 2
resampMa2acov <- Re(fft(resampMa2PSD, inverse = TRUE))

plot(resampMa2acov[1:30], xlab = "lag", ylab = "autocovariance", ylim = c(0, 15))

resampMa2 <- apply(resampMa2T, 2, function(x) zapsmall(Re(fft(x, inverse = TRUE) / N)))
tmpf <- function(x) acf(x, type = "covariance", plot = FALSE, demean = FALSE)$acf[,1,1]
points(rowMeans(apply(resampMa2, 2, tmpf)), pch = 3, col = 2)
legend("topright", pch = c(1, 3), col = c(1, 2), legend = c("PSD method", "time-domain method"))

```

The autocovariance appears to be signifincant for lags up to 20 in the moving average of 2 observations, a bit longer than was the case for original simulation. 

## Disclaimer

The content is solely the responsibility of the authors and does not
necessarily reflect the official views of the National Institutes of
Health.

## References

